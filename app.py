from dotenv import load_dotenv
load_dotenv()

import os
import shutil
import gradio as gr
import pandas as pd
import plotly.express as px
import plotly.io as pio
from math import ceil
from embedding_manager import update_vector_store
from retrieval import create_conversational_chain
from langchain_community.vectorstores import Chroma
from langchain_community.chat_models import ChatOpenAI
from data_analyzer import generate_dashboards_and_commentary
from langchain_community.document_loaders import PyPDFLoader, UnstructuredWordDocumentLoader, TextLoader


# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø—É—Ç–∏.
FILES_FOLDER = "files"
CHROMA_DB = "chroma_db"

os.makedirs(FILES_FOLDER, exist_ok=True)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–º –∑–∞–ø—Ä–æ—Å–µ.
LAST_USED_CHUNKS = []

vectorstore = update_vector_store(FILES_FOLDER, persist_directory=CHROMA_DB)
qa_chain = create_conversational_chain(vectorstore)

def answer_query(query, chat_history):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –ø–æ–º–æ—â—å—é —Ü–µ–ø–æ—á–∫–∏ ConversationalRetrievalChain.
    –î–æ–±–∞–≤–ª—è–µ—Ç –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
    """
    global LAST_USED_CHUNKS
    if not query.strip():
        return "", chat_history
    result = qa_chain({"question": query, "chat_history": chat_history})
    answer = result["answer"]
    LAST_USED_CHUNKS = result.get("source_documents", [])
    chat_history.append((query, answer))
    return "", chat_history

def clear_history():
    """
    –û—á–∏—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞.
    """
    qa_chain.memory.clear()
    return []

def view_used_chunks():
    """
    –î–ª—è –æ—Ç–ª–∞–¥–∫–∏: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ —á–∞–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞.
    –ö–∞–∂–¥—ã–π —Ç–µ–∫—Å—Ç —á–∞–Ω–∫–∞ —Ä–∞–∑–¥–µ–ª—è–µ—Ç—Å—è –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π.
    """
    if not LAST_USED_CHUNKS:
        return "–ü–æ–∫–∞ –Ω–µ –±—ã–ª–æ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞."
    lines = []
    for doc in LAST_USED_CHUNKS:
        content = doc.page_content.strip() if hasattr(doc, "page_content") else str(doc)
        lines.append(content)
    return "\n\n".join(lines)

def upload_file(file_obj):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞:
      - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª –≤ –ø–∞–ø–∫–µ files.
      - –û–±–Ω–æ–≤–ª—è–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏ —Ü–µ–ø–æ—á–∫—É QA.
    """
    if file_obj is None:
        return "–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω."
    
    file_name = os.path.basename(file_obj.name) if hasattr(file_obj, "name") else str(file_obj)
    dest_path = os.path.join(FILES_FOLDER, file_name)
    
    if hasattr(file_obj, "read"):
        with open(dest_path, "wb") as f:
            f.write(file_obj.read())
    else:
        if os.path.abspath(file_obj) == os.path.abspath(dest_path):
            return f"–§–∞–π–ª '{file_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."
        shutil.copy(file_obj, dest_path)
    
    global vectorstore, qa_chain
    vectorstore = update_vector_store(FILES_FOLDER, persist_directory=CHROMA_DB)
    qa_chain = create_conversational_chain(vectorstore)
    
    return f"–§–∞–π–ª '{file_name}' –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ."

def get_chat_history_text(chat_history):
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ (—Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π) –≤ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É.
    """
    if not chat_history:
        return "–ù–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞."
    lines = []
    for turn in chat_history:
        user, assistant = turn
        lines.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user}\n–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: {assistant}")
    return "\n\n".join(lines)

def analyze_conversation(chat_history):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏ –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑.
    –ï—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.
    """
    conversation_text = get_chat_history_text(chat_history)
    if conversation_text.strip() == "–ù–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞.":
        return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."
    
    analysis_prompt = (
        "–¢—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫ –≤ —Å—Ñ–µ—Ä–µ —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —É—Å–ª—É–≥. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–π –Ω–∏–∂–µ —Ä–∞–∑–≥–æ–≤–æ—Ä –∏ –¥–∞–π –∫—Ä–∞—Ç–∫–∏–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n\n"
        "1. –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ —Ç–µ–º—ã (–¥–æ 3 –ø—É–Ω–∫—Ç–æ–≤).\n"
        "2. –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã (–¥–æ 2 –ø—É–Ω–∫—Ç–æ–≤).\n"
        "3. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–¥–æ 3 –ø—É–Ω–∫—Ç–æ–≤).\n\n"
        "–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –≤ –≤–∏–¥–µ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–ª–∏ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞, –±–µ–∑ –∏–∑–±—ã—Ç–æ—á–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π. –ù–µ –≤–∫–ª—é—á–∞–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –∏–ª–∏ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è.\n\n"
        "–†–∞–∑–≥–æ–≤–æ—Ä:\n" + conversation_text + "\n\n"
        "–ê–Ω–∞–ª–∏–∑:"
    )
    
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.2)
    analysis_result = llm.invoke(analysis_prompt)
    return analysis_result


def custom_prompt_response(user_prompt):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç, –≤–≤–µ–¥—ë–Ω–Ω—ã–π –≤—Ä—É—á–Ω—É—é.
    """
    if not user_prompt.strip():
        return "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º–ø—Ç."
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.2)
    response = llm.invoke(user_prompt)
    return response

def show_dashboards():
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –¥–∞—à–±–æ—Ä–¥, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Ä–µ–∑—é–º–µ.
    –ï—Å–ª–∏ —Ñ–∞–π–ª analysis_summary.txt —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –æ–Ω –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è.
    –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è.
    """
    combined_fig, commentary, summary_text = generate_dashboards_and_commentary()
    summary_path = os.path.join(FILES_FOLDER, "analysis_summary.txt")
    
    # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤–æ–µ —Ä–µ–∑—é–º–µ.
    if not os.path.exists(summary_path):
        with open(summary_path, "w", encoding="utf-8") as f:
            f.write(summary_text)
    
    global vectorstore, qa_chain
    vectorstore = update_vector_store(FILES_FOLDER, persist_directory=CHROMA_DB)
    qa_chain = create_conversational_chain(vectorstore)
    return combined_fig, commentary


def generate_individual_dashboards():
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ø–æ –¥–∞–Ω–Ω—ã–º CSV –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≥—Ä–∞—Ñ–∏–∫–æ–≤, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Ä–µ–∑—é–º–µ.
    –õ–æ–≥–∏–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞ generate_dashboards_and_commentary, –Ω–æ –±–µ–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —á–µ—Ä–µ–∑ make_subplots.
    """
    sales_path = os.path.join("Datasets", "sales_data.csv")
    sentiment_path = os.path.join("Datasets", "customer_sentiment.csv")
    
    try:
        df_sales = pd.read_csv(sales_path, encoding="utf-8")
    except Exception as e:
        return [], f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ sales_data.csv: {e}", ""
    
    try:
        df_sentiment = pd.read_csv(sentiment_path, encoding="utf-8")
    except Exception as e:
        return [], f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ customer_sentiment.csv: {e}", ""
    
    figs = []
    
    if "Date" in df_sales.columns and "Sales" in df_sales.columns:
        df_sales["Date"] = pd.to_datetime(df_sales["Date"], errors="coerce")
        df_sales_sorted = df_sales.sort_values("Date")
        fig_line = px.line(df_sales_sorted, x="Date", y="Sales", title="–¢—Ä–µ–Ω–¥ –ø—Ä–æ–¥–∞–∂ –ø–æ –¥–∞—Ç–∞–º")
        figs.append(fig_line)
    
    if "Region" in df_sales.columns and "Sales" in df_sales.columns:
        fig_bar = px.bar(df_sales, x="Region", y="Sales", title="–ü—Ä–æ–¥–∞–∂–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º", color="Region")
        figs.append(fig_bar)
    
    if "Product" in df_sales.columns and "Sales" in df_sales.columns:
        product_group = df_sales.groupby("Product")["Sales"].sum().reset_index()
        fig_pie = px.pie(product_group, names="Product", values="Sales", title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–∂ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º")
        figs.append(fig_pie)
    
    if "Sentiment" in df_sentiment.columns:
        sentiment_count = df_sentiment["Sentiment"].value_counts().reset_index()
        sentiment_count.columns = ["Sentiment", "Count"]
        fig_sent = px.bar(sentiment_count, x="Sentiment", y="Count", title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –ø–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏", color="Sentiment")
        figs.append(fig_sent)
    
    if "Date" in df_sentiment.columns:
        df_sentiment["Date"] = pd.to_datetime(df_sentiment["Date"], errors="coerce")
        df_sentiment_sorted = df_sentiment.sort_values("Date")
        fig_sent_timeline = px.histogram(df_sentiment_sorted, x="Date", title="–ß–∞—Å—Ç–æ—Ç–∞ –æ—Ç–∑—ã–≤–æ–≤ –ø–æ –¥–∞—Ç–∞–º")
        figs.append(fig_sent_timeline)
    
    total_sales = df_sales["Sales"].sum() if "Sales" in df_sales.columns else 0
    avg_sales = df_sales["Sales"].mean() if "Sales" in df_sales.columns else 0
    sales_summary = f"sales_data.csv: {len(df_sales)} —Å—Ç—Ä–æ–∫, —Å—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ = {total_sales}, —Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–∞–∂–∞ = {avg_sales:.2f}."
    
    total_reviews = len(df_sentiment)
    pos = (df_sentiment["Sentiment"]=="Positive").sum() if "Sentiment" in df_sentiment.columns else 0
    neu = (df_sentiment["Sentiment"]=="Neutral").sum() if "Sentiment" in df_sentiment.columns else 0
    neg = (df_sentiment["Sentiment"]=="Negative").sum() if "Sentiment" in df_sentiment.columns else 0
    sentiment_summary = f"customer_sentiment.csv: {total_reviews} –æ—Ç–∑—ã–≤–æ–≤, –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö: {pos}, –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö: {neu}, –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö: {neg}."
    
    summary_text = sales_summary + "\n" + sentiment_summary

    prompt = (
        "–¢—ã –æ–ø—ã—Ç–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –≤ —Å—Ñ–µ—Ä–µ —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —É—Å–ª—É–≥. –ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º –∏ –æ—Ç–∑—ã–≤–∞–º –∫–ª–∏–µ–Ω—Ç–æ–≤:\n\n"
        f"{summary_text}\n\n"
        "1. –†–∞—Å—Å—á–∏—Ç–∞–π –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö, –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö –∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤.\n"
        "2. –í—ã–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –ø—Ä–æ–±–ª–µ–º—ã.\n"
        "3. –û–ø—Ä–µ–¥–µ–ª–∏ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∫–æ–º–ø–∞–Ω–∏–∏, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã.\n"
        "4. –î–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤.\n\n"
        "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Ü–∏—Ñ—Ä–∞–º–∏ –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏."
    )
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.2)
    commentary = llm.invoke(prompt)
    
    return figs, commentary, summary_text

def show_individual_dashboards():
    """
    –í—ã–∑—ã–≤–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é generate_individual_dashboards(), –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–ø–∏—Å–æ–∫ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤ HTML –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –≤–º–µ—Å—Ç–µ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–º.
    """
    figs, commentary, _ = generate_individual_dashboards()
    html_parts = []
    for fig in figs:
        html_parts.append(pio.to_html(fig, full_html=False, include_plotlyjs='cdn'))
    html_combined = "<br><hr><br>".join(html_parts)
    return html_combined, commentary

with gr.Blocks(title="RAG –°–∏—Å—Ç–µ–º–∞") as demo:
    with gr.Tab("–ß–∞—Ç"):
        gr.Markdown("# RAG (–ß–∞—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)")
        chatbot = gr.Chatbot(label="–ß–∞—Ç")
        with gr.Row():
            query_input = gr.Textbox(
                placeholder="–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å...",
                show_label=False,
                container=True,
                scale=9
            )
            send_button = gr.Button("‚¨Ü", variant="primary", size="sm", scale=1)
            clear_button = gr.Button("üóëÔ∏è", size="sm", scale=1)
        query_input.submit(fn=answer_query, inputs=[query_input, chatbot], outputs=[query_input, chatbot])
        send_button.click(fn=answer_query, inputs=[query_input, chatbot], outputs=[query_input, chatbot])
        clear_button.click(fn=clear_history, outputs=chatbot)
    
    with gr.Tab("–í—ã–≥—Ä—É–∑–∫–∞"):
        gr.Markdown("# –í—ã–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã")
        file_input = gr.File(label="–î–æ–∫—É–º–µ–Ω—Ç—ã –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º", file_types=[".pdf", ".docx", ".txt"])
        upload_button = gr.Button("–ó–∞–≥—Ä—É–∑–∏—Ç—å")
        upload_output = gr.Textbox(label="–°—Ç–∞—Ç—É—Å", lines=2)
        upload_button.click(fn=upload_file, inputs=file_input, outputs=upload_output)
    
    with gr.Tab("DBLookup"):
        gr.Markdown("# –ß–∞–Ω–∫–∏, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
        view_chunks_button = gr.Button("–í—ã–≤–µ—Å—Ç–∏ —á–∞–Ω–∫–∏")
        chunks_output = gr.Textbox(label="–ß–∞–Ω–∫–∏ (—Ä–∞–∑–¥–µ–ª–µ–Ω—ã –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π)", lines=10)
        view_chunks_button.click(fn=view_used_chunks, outputs=chunks_output)
    
    with gr.Tab("–ê–Ω–∞–ª–∏—Ç–∏–∫–∞"):
        gr.Markdown("# –ê–Ω–∞–ª–∏–∑ —á–∞—Ç–∞")
        analyze_button = gr.Button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑")
        analysis_output = gr.Textbox(label="–ü–æ –∏—Å—Ç–æ—Ä–∏–∏ –ø–µ—Ä–µ–ø–∏—Å–æ–∫ (–í–æ–æ–±—â–µ, –ø–æ–∫–∞ –æ—á–µ–Ω—å –∫–æ—Å—è—á–Ω–æ. –ü–ª—é—Å, –ø–æ–∫–∞ —á—Ç–æ –Ω–µ —Å–æ–≤—Å–µ–º –ø–æ–Ω—è—Ç–Ω—ã–π use-case, –∏–±–æ –≤—Å–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ, –≤ –±—É–¥—É—â–µ–º –¥–æ—Ä–∞–±–æ—Ç–∞–µ–º.)", lines=10)
        analyze_button.click(fn=analyze_conversation, inputs=chatbot, outputs=analysis_output)
    
    with gr.Tab("–î–∞—à–±–æ—Ä–¥—ã"):
        gr.Markdown("## –î–∞—à–±–æ—Ä–¥—ã –ø–æ –¥–∞–Ω–Ω—ã–º CSV")
        dashboards_plot = gr.Plot(label="–ì—Ä–∞—Ñ–∏–∫–∏")  # –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π dashboard
        dashboards_comment = gr.Textbox(label="–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ—Ç –ò–ò", lines=10)
        dashboards_button = gr.Button("–û–±–Ω–æ–≤–∏—Ç—å –¥–∞—à–±–æ—Ä–¥—ã")
        dashboards_button.click(fn=show_dashboards, inputs=None, outputs=[dashboards_plot, dashboards_comment])
    
demo.launch(share=True)
